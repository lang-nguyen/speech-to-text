{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the environment"
      ],
      "metadata": {
        "id": "MAbwP8cyu8PX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "V7BMIa7oudrt",
        "outputId": "0f5522f3-2419-468f-d849-fba26178ee3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "!pip install torchaudio datasets jiwer gradio transformers noisereduce -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import library"
      ],
      "metadata": {
        "id": "bPqFuCDLWFNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "from datasets import Dataset\n",
        "from tqdm import tqdm\n",
        "from whisper.normalizers import EnglishTextNormalizer\n",
        "from IPython.display import display, clear_output\n",
        "import os\n",
        "import glob\n",
        "import whisper\n",
        "import torchaudio\n",
        "import torch\n",
        "import pandas as pd\n",
        "import jiwer\n",
        "import noisereduce as nr"
      ],
      "metadata": {
        "id": "swzFRbUUW3Wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Drive"
      ],
      "metadata": {
        "id": "kKeWJLNWYTxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "WORK_DIR = '/content/drive/MyDrive/Intership-Assignment/BLULEAP-AI'\n",
        "print(f\"Working directory set to: {WORK_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XbEbqN-KubJH",
        "outputId": "fb6a08d2-cfaf-448f-a096-372e7700ac06"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Working directory set to: /content/drive/MyDrive/Intership-Assignment/BLULEAP-AI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the dataset"
      ],
      "metadata": {
        "id": "aU3iAZHhuw-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = f\"{WORK_DIR}/Datasets/LibriSpeech\"\n",
        "\n",
        "# Get all .flac files\n",
        "audio_files = sorted(glob.glob(f\"{DATA_DIR}/**/*.flac\", recursive=True))\n",
        "print(f\"Found {len(audio_files)} audio files.\")\n",
        "\n",
        "# Read and merge text based on file ID\n",
        "texts = []\n",
        "for audio_file in audio_files:\n",
        "    folder = os.path.dirname(audio_file)\n",
        "    trans_files = glob.glob(f\"{folder}/*.trans.txt\")\n",
        "    if not trans_files:\n",
        "        texts.append(\"No text available\")\n",
        "        continue\n",
        "    trans_file = trans_files[0]\n",
        "    # Create a dictionary mapping ID -> text from .trans.txt\n",
        "    trans_dict = {}\n",
        "    with open(trans_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                parts = line.strip().split(maxsplit=1)\n",
        "                if len(parts) == 2:\n",
        "                    trans_dict[parts[0]] = parts[1]\n",
        "\n",
        "    # Extract ID from the .flac file name\n",
        "    flac_id = os.path.basename(audio_file).replace(\".flac\", \"\")\n",
        "    text = trans_dict.get(flac_id, \"No text available\")\n",
        "    texts.append(text)\n",
        "\n",
        "# Create dataset\n",
        "dataset = Dataset.from_dict({\"audio\": audio_files, \"text\": texts})\n",
        "print(f\"Loaded {len(dataset)} samples from {DATA_DIR}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hX-juLNZvKNT",
        "outputId": "27f75d90-24be-43d2-fd73-8a66bd82f97f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2703 audio files.\n",
            "Loaded 2703 samples from /content/drive/MyDrive/Intership-Assignment/BLULEAP-AI/Datasets/LibriSpeech.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build an STT system with Whisper"
      ],
      "metadata": {
        "id": "qxX5xm8vzGBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model (base.en)\n",
        "model = whisper.load_model(\"base.en\")\n",
        "print(f\"Model loaded on {model.device}\")\n",
        "\n",
        "# Process audio\n",
        "def process_audio(audio_path):\n",
        "    try:\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)\n",
        "        return whisper.pad_or_trim(waveform.flatten()), sample_rate\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {audio_path}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Prepare batch\n",
        "def prepare_batch(audio_paths, texts):\n",
        "    audios = []\n",
        "    for audio_path, text in zip(audio_paths, texts):\n",
        "        audio, _ = process_audio(audio_path)\n",
        "        if audio is not None:\n",
        "            audios.append(audio)\n",
        "    if audios:\n",
        "        batch_audios = torch.stack(audios).to(model.device)\n",
        "        return batch_audios, texts[:len(audios)]\n",
        "    return None, None\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# STT\n",
        "transcriptions = []\n",
        "for i in tqdm(range(0, len(dataset), BATCH_SIZE), desc=\"Transcribing\"):\n",
        "    batch_paths = dataset['audio'][i:i + BATCH_SIZE]\n",
        "    batch_texts = dataset['text'][i:i + BATCH_SIZE]\n",
        "    batch_audios, valid_texts = prepare_batch(batch_paths, batch_texts)\n",
        "    if batch_audios is not None:\n",
        "        mels = whisper.log_mel_spectrogram(batch_audios)\n",
        "        results = model.decode(mels, options=whisper.DecodingOptions(language=\"en\", without_timestamps=True))\n",
        "        transcriptions.extend([result.text.strip() for result in results])\n",
        "\n",
        "# Save results\n",
        "with open(f\"{WORK_DIR}/transcriptions.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for t in transcriptions:\n",
        "        f.write(f\"{t}\\n\")\n",
        "print(f\"Transcriptions saved to {WORK_DIR}/transcriptions.txt. Total: {len(transcriptions)} samples.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VtMMwNUzJUe",
        "outputId": "ddfdeb41-0086-4d49-a5e9-972eff6b0d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Transcribing: 100%|██████████| 169/169 [37:21<00:00, 13.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcriptions saved to /content/drive/MyDrive/Intership-Assignment/BLULEAP-AI/transcriptions.txt. Total: 2703 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test and Evaluate"
      ],
      "metadata": {
        "id": "OdkH11PyUm7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check\n",
        "print(f\"Transcriptions: {len(transcriptions)}, Dataset: {len(dataset)}\")\n",
        "if len(transcriptions) == len(dataset): print(\"Success!\")\n",
        "\n",
        "for i in range(min(5, len(dataset))):\n",
        "    print(f\"Sample {i+1}: GT: {dataset[i]['text']}, Trans: {transcriptions[i]}\")\n",
        "\n",
        "# DataFrame\n",
        "data = pd.DataFrame({\"reference\": dataset['text'], \"hypothesis\": transcriptions})\n",
        "print(\"\\n5 dòng đầu:\", data.head())\n",
        "\n",
        "# Normalize\n",
        "normalizer = EnglishTextNormalizer()\n",
        "data[\"ref_clean\"] = [normalizer(t) for t in data[\"reference\"]]\n",
        "data[\"hyp_clean\"] = [normalizer(t) for t in data[\"hypothesis\"]]\n",
        "print(\"\\n5 dòng đầu (đã chuẩn hóa):\", data[[\"ref_clean\", \"hyp_clean\"]].head())\n",
        "\n",
        "# Check the file\n",
        "with open(f\"{WORK_DIR}/transcriptions.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    print(\"\\n5 dòng file:\", [line.strip() for line in f.readlines()[:5]])"
      ],
      "metadata": {
        "id": "SXN6ccjEUo9C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e33baa-7a21-4918-e0b8-1c3a8ecd7a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcriptions: 2703, Dataset: 2703\n",
            "Success!\n",
            "Sample 1: GT: MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL, Trans: Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.\n",
            "Sample 2: GT: NOR IS MISTER QUILTER'S MANNER LESS INTERESTING THAN HIS MATTER, Trans: Nor is Mr. Quilter's manner less interesting than his matter.\n",
            "Sample 3: GT: HE TELLS US THAT AT THIS FESTIVE SEASON OF THE YEAR WITH CHRISTMAS AND ROAST BEEF LOOMING BEFORE US SIMILES DRAWN FROM EATING AND ITS RESULTS OCCUR MOST READILY TO THE MIND, Trans: He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind.\n",
            "Sample 4: GT: HE HAS GRAVE DOUBTS WHETHER SIR FREDERICK LEIGHTON'S WORK IS REALLY GREEK AFTER ALL AND CAN DISCOVER IN IT BUT LITTLE OF ROCKY ITHACA, Trans: He has grieved doubts whether Sir Frederick Layton's work is really Greek after all, and can discover in it but little of rocky Ithaca.\n",
            "Sample 5: GT: LINNELL'S PICTURES ARE A SORT OF UP GUARDS AND AT EM PAINTINGS AND MASON'S EXQUISITE IDYLLS ARE AS NATIONAL AS A JINGO POEM MISTER BIRKET FOSTER'S LANDSCAPES SMILE AT ONE MUCH IN THE SAME WAY THAT MISTER CARKER USED TO FLASH HIS TEETH AND MISTER JOHN COLLIER GIVES HIS SITTER A CHEERFUL SLAP ON THE BACK BEFORE HE SAYS LIKE A SHAMPOOER IN A TURKISH BATH NEXT MAN, Trans: Lynille's pictures are a sort of up-guards and atom paintings, and Mason's exquisite idols are as national as a jingo poem. Mr. Burkett Foster's landscapes smile at one much in the same way that Mr. Carkerer used to flash his teeth, and Mr. John Collier gives his sitter a cheerful slap on the back before he says like a shampoo or a Turkish bath. Next, man!\n",
            "\n",
            "5 dòng đầu:                                            reference  \\\n",
            "0  MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CL...   \n",
            "1  NOR IS MISTER QUILTER'S MANNER LESS INTERESTIN...   \n",
            "2  HE TELLS US THAT AT THIS FESTIVE SEASON OF THE...   \n",
            "3  HE HAS GRAVE DOUBTS WHETHER SIR FREDERICK LEIG...   \n",
            "4  LINNELL'S PICTURES ARE A SORT OF UP GUARDS AND...   \n",
            "\n",
            "                                          hypothesis  \n",
            "0  Mr. Quilter is the apostle of the middle class...  \n",
            "1  Nor is Mr. Quilter's manner less interesting t...  \n",
            "2  He tells us that at this festive season of the...  \n",
            "3  He has grieved doubts whether Sir Frederick La...  \n",
            "4  Lynille's pictures are a sort of up-guards and...  \n",
            "\n",
            "5 dòng đầu (đã chuẩn hóa):                                            ref_clean  \\\n",
            "0  mister quilter is the apostle of the middle cl...   \n",
            "1  nor is mister quilter is manner less interesti...   \n",
            "2  he tells us that at this festive season of the...   \n",
            "3  he has grave doubts whether sir frederick leig...   \n",
            "4  linnell is pictures are a sort of up guards an...   \n",
            "\n",
            "                                           hyp_clean  \n",
            "0  mister quilter is the apostle of the middle cl...  \n",
            "1  nor is mister quilter is manner less interesti...  \n",
            "2  he tells us that at this festive season of the...  \n",
            "3  he has grieved doubts whether sir frederick la...  \n",
            "4  lynille is pictures are a sort of up guards an...  \n",
            "\n",
            "5 dòng file: ['Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.', \"Nor is Mr. Quilter's manner less interesting than his matter.\", 'He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind.', \"He has grieved doubts whether Sir Frederick Layton's work is really Greek after all, and can discover in it but little of rocky Ithaca.\", \"Lynille's pictures are a sort of up-guards and atom paintings, and Mason's exquisite idols are as national as a jingo poem. Mr. Burkett Foster's landscapes smile at one much in the same way that Mr. Carkerer used to flash his teeth, and Mr. John Collier gives his sitter a cheerful slap on the back before he says like a shampoo or a Turkish bath. Next, man!\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate WER with the base model\n",
        "wers = [jiwer.wer(gt, hyp) for gt, hyp in zip(data[\"ref_clean\"], data[\"hyp_clean\"])]\n",
        "average_wer = sum(wers) / len(wers) if wers else 0\n",
        "print(f\"\\nAverage WER with base model: {average_wer * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBjhcY3tzv--",
        "outputId": "e94bc103-3ce7-4766-dc0e-063659a6e20b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average WER with base model: 5.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improve WER"
      ],
      "metadata": {
        "id": "_eTgwfBiwsZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Improvement: Try the small model\n",
        "model_small = whisper.load_model(\"small.en\")\n",
        "print(f\"Model small loaded on {model_small.device}\")\n",
        "\n",
        "transcriptions_small = []\n",
        "for i in tqdm(range(0, len(dataset), BATCH_SIZE), desc=\"Transcribing small\"):\n",
        "    batch_paths = dataset['audio'][i:i + BATCH_SIZE]\n",
        "    batch_texts = dataset['text'][i:i + BATCH_SIZE]\n",
        "    batch_audios, valid_texts = prepare_batch(batch_paths, batch_texts)\n",
        "    if batch_audios is not None:\n",
        "        mels = whisper.log_mel_spectrogram(batch_audios)\n",
        "        results = model_small.decode(mels, options=whisper.DecodingOptions(language=\"en\", without_timestamps=True))\n",
        "        transcriptions_small.extend([result.text.strip() for result in results])\n",
        "\n",
        "# Calculate WER with the small model\n",
        "wers_small = [jiwer.wer(gt, hyp) for gt, hyp in zip(data[\"ref_clean\"], [normalizer(t) for t in transcriptions_small[:len(data[\"ref_clean\"])]])]\n",
        "average_wer_small = sum(wers_small) / len(wers_small) if wers_small else 0\n",
        "print(f\"Average WER with small model: {average_wer_small * 100:.2f}%\")\n",
        "\n",
        "# Save result\n",
        "with open(f\"{WORK_DIR}/wer_results.txt\", \"w\") as f:\n",
        "    f.write(f\"Base WER: {average_wer * 100:.2f}%\\nSmall WER: {average_wer_small * 100:.2f}%\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMvJH8x2z1ZE",
        "outputId": "e35df934-3234-40cd-c4d0-269a1ad10156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:08<00:00, 55.2MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model small loaded on cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Transcribing small: 100%|██████████| 169/169 [04:31<00:00,  1.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average WER with small model: 3.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handle noise and multilingual processing"
      ],
      "metadata": {
        "id": "69mO1fPF1-LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload the model\n",
        "model = whisper.load_model(\"base.en\")\n",
        "print(f\"Model loaded on {model.device}\")\n",
        "\n",
        "# Audio processing function with noise reduction and shape normalization\n",
        "def process_audio_with_noise(audio_path):\n",
        "    waveform, sample_rate = torchaudio.load(audio_path)\n",
        "    audio_np = waveform.cpu().numpy().mean(axis=0) if waveform.dim() > 1 else waveform.cpu().numpy()\n",
        "    noise_reduced = nr.reduce_noise(y=audio_np, sr=sample_rate)\n",
        "    audio_tensor = torch.tensor(noise_reduced).to(model.device)\n",
        "    return whisper.pad_or_trim(audio_tensor), sample_rate\n",
        "\n",
        "# Test noise reduction\n",
        "audio, sample_rate = process_audio_with_noise(dataset[0]['audio'])\n",
        "if audio is not None:\n",
        "    mels = whisper.log_mel_spectrogram(audio.unsqueeze(0))\n",
        "    result_noise = model.decode(mels, options=whisper.DecodingOptions(language=\"en\", without_timestamps=True))[0]\n",
        "    print(f\"Transcription with noise reduction: {result_noise.text}\")\n",
        "\n",
        "# Test multilingual\n",
        "if audio is not None:\n",
        "    result_multi = model.decode(mels, options=whisper.DecodingOptions(language=\"fr\", without_timestamps=True))[0]\n",
        "    print(f\"Transcription in French: {result_multi.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oiCLeuey2C5A",
        "outputId": "c9b03c39-5b89-4d54-a52b-9f69b89a9fe0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on cuda:0\n",
            "Transcription with noise reduction: Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.\n",
            "Transcription in French: Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo"
      ],
      "metadata": {
        "id": "vdMhZs51ad0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model = whisper.load_model(\"base.en\")\n",
        "print(f\"Model loaded on {model.device}\")\n",
        "\n",
        "# Processing\n",
        "def transcribe_audio(audio_path, reduce_noise=False, language=\"en\"):\n",
        "    waveform, sample_rate = torchaudio.load(audio_path)\n",
        "    if reduce_noise:\n",
        "        audio_np = waveform.cpu().numpy().mean(axis=0)\n",
        "        noise_reduced = nr.reduce_noise(y=audio_np, sr=sample_rate)\n",
        "        audio = torch.tensor(noise_reduced).to(model.device)\n",
        "    else:\n",
        "        audio = waveform.to(model.device)\n",
        "    audio_padded = whisper.pad_or_trim(audio)\n",
        "    mels = whisper.log_mel_spectrogram(audio_padded.unsqueeze(0))\n",
        "    result = model.decode(mels, options=whisper.DecodingOptions(language=language, without_timestamps=True))[0]\n",
        "    return result.text\n",
        "\n",
        "# Colab Forms\n",
        "uploaded_file = files.upload()\n",
        "reduce_noise = \"Reduce Noise\" #@param {type:\"boolean\"}\n",
        "language = \"en\" #@param [\"en\", \"fr\"]\n",
        "\n",
        "if uploaded_file:\n",
        "    audio_path = list(uploaded_file.keys())[0]\n",
        "    transcription = transcribe_audio(audio_path, reduce_noise, language)\n",
        "    clear_output()\n",
        "    print(f\"Transcription: {transcription}\")\n",
        "    print(f\"Options: Reduce Noise={reduce_noise}, Language={language}\")\n",
        "else:\n",
        "    print(\"Please upload an audio file (.wav, .flac) to proceed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "y9a1jGz8aWrP",
        "outputId": "8a80f978-3af3-480f-a65a-3948fa391d12"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription: Therefore, my answer is with greater care that he may hear me who is weeping yonder so that the sin and dull be of one measure.\n",
            "Options: Reduce Noise=Reduce Noise, Language=en\n"
          ]
        }
      ]
    }
  ]
}